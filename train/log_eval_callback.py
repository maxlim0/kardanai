from transformers import TrainerCallback
import torch

class LogEvalCallback(TrainerCallback):
    def __init__(self, tokenizer):
        super().__init__()
        self.tokenizer = tokenizer

    def on_evaluate(self, args, state, control, model, eval_dataloader, **kwargs):
        print("\nüîπ –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –ø—Ä–∏–º–µ—Ä–µ...\n")
        for batch in eval_dataloader:
            inputs = {k: v.to(model.device) for k, v in batch.items()}
            with torch.no_grad():
                output_ids = model.generate(inputs["input_ids"], max_new_tokens=50)
            print("üü¢ –í–æ–ø—Ä–æ—Å:", self.tokenizer.decode(inputs["input_ids"][0], skip_special_tokens=True))
            print("üü° –û–∂–∏–¥–∞–µ–º—ã–π –æ—Ç–≤–µ—Ç:", self.tokenizer.decode(inputs["labels"][0], skip_special_tokens=True))
            print("üî¥ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç:", self.tokenizer.decode(output_ids[0], skip_special_tokens=True))
            break  # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –ø—Ä–∏–º–µ—Ä